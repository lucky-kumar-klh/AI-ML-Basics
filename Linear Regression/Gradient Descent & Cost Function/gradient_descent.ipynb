{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y):\n",
    "    learning_rate = 0.001\n",
    "    m_curr = b_curr = 0\n",
    "    iterations = 1000\n",
    "    n = len(x)\n",
    "    for _ in range(iterations):\n",
    "        # Find y predicted\n",
    "        y_predicted = (x * m_curr) + b_curr\n",
    "        # Calculate Cost Function \n",
    "        cost = (1/n) * sum([val**2 for val in (y - y_predicted)])\n",
    "        # Get derivatives of m & b\n",
    "        m_d = -(2/n) * sum(x*(y - y_predicted))\n",
    "        b_d = -(2/n) * sum(y - y_predicted)\n",
    "        # Update current values of m & b\n",
    "        m_curr = m_curr - (learning_rate * m_d)\n",
    "        b_curr = b_curr - (learning_rate * b_d)\n",
    "\n",
    "        print(f\"m = {m_curr}, b = {b_curr}, cost = {cost}: itr {_+1}\")\n",
    "    \n",
    "\n",
    "\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "gradient_descent(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKLearn -> m = 1.0177362378569328 & b = 1.9152193111569034\n",
      "Score: 0.8990561457295679\n",
      "Gradient Descent -> m = 1.0445228751752675 & b = 0.01691985520723526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "m, b = 0, 0\n",
    "\n",
    "df = pd.read_csv(\"test_scores.csv\") \n",
    "\n",
    "def sklearn_model(x, y):\n",
    "    global df\n",
    "    reg = linear_model.LinearRegression()\n",
    "    reg.fit(x.reshape(-1, 1), y)  # -1 (unkown) rows & 1 col 2D Array\n",
    "\n",
    "    print(f\"SKLearn -> m = {reg.coef_[0]} & b = {reg.intercept_}\")\n",
    "\n",
    "    predicted_cs = reg.predict(df[['math']])\n",
    "    df['Predicted_CS_SKlearn'] = predicted_cs\n",
    "    df.to_csv(\"test_scores.csv\", index = False)\n",
    "\n",
    "    print(\"Score:\", reg.score(x.reshape(-1, 1), y))\n",
    "\n",
    "\n",
    "def gradient_descent_algo(x, y):\n",
    "    global m, b\n",
    "    iterations, alpha, n, previous_cost = 100, 0.0001, len(x), 0\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        y_pred = (m * x) + b   \n",
    "        cost = (1/n) * sum([val**2 for val in (y - y_pred)])\n",
    "        m_d = -(2/n) * sum(x * (y - y_pred))\n",
    "        b_d = -(2/n) * sum(y - y_pred)\n",
    "\n",
    "        m = m - (alpha * m_d)\n",
    "        b = b - (alpha * b_d)\n",
    "\n",
    "        if math.isclose(cost, previous_cost, rel_tol = 1e-20):  # Check for Convergence of Gradient Descent\n",
    "            break\n",
    "\n",
    "        previous_cost = cost\n",
    "\n",
    "        # print(f\"m = {m}, b = {b}, cost = {cost}: itr {_+1}\")\n",
    "\n",
    "    optimal_m, optimal_b = m, b\n",
    "    predicted_cs = []\n",
    "    for input_x in df['math']:\n",
    "        value = (optimal_m * input_x) + optimal_b\n",
    "        predicted_cs.append(value)\n",
    "    \n",
    "    df['Predicted_CS_Gradient_Descent'] = predicted_cs\n",
    "    df.to_csv(\"test_scores.csv\", index = False)\n",
    "\n",
    "\n",
    "x = np.array(df['math'])\n",
    "y = np.array(df['cs'])\n",
    "\n",
    "gradient_descent_algo(x, y)\n",
    "sklearn_model(x, y)\n",
    "\n",
    "print(f\"Gradient Descent -> m = {m} & b = {b}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing a Model in a File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Creating & Training Model\n",
    "data = pd.read_csv(\"test_scores.csv\")\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(data[['math']], data['cs'])\n",
    "\n",
    "\n",
    "# Storing the model in a File in order to use it\n",
    "\n",
    "joblib.dump(reg, \"test_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
